
# coding: utf-8

# In[1]:


from google.cloud import vision


# In[44]:


import os 
import io 
from google.cloud import vision 
from matplotlib import pyplot as plt 
from matplotlib import patches as pch 

os.environ["GOOGLE_APPLICATION_CREDENTIALS"]="/Users/akshaykumar/Documents/load-balancer-gcp.json" 

client = vision.ImageAnnotatorClient() 

f = '/Users/akshaykumar/Downloads/IMG_0123.png'
with io.open(f, 'rb') as image: 
    content = image.read() 

image = vision.types.Image(content = content) 
response = client.text_detection(image = image) 
texts = response.text_annotations 

# a = plt.imread(f) 
# fig, ax = plt.subplots(1) 
# ax.imshow(a) 
x = []
for text in texts: 
    x.append(text.description)
    break
#     vertices = ([(vertex.x, vertex.y) 
#                 for vertex in text.bounding_poly.vertices]) 
#     print('Vertices covering text: {}\n\n'.format(vertices)) 
#     rect = pch.Rectangle(vertices[0], (vertices[1][0] - vertices[0][0]), 
#         (vertices[2][1] - vertices[0][1]), linewidth = 1, 
#                                 edgecolor ='r', facecolor ='none') 
#     ax.add_patch(rect) 
# plt.show() 
y = str(x[0])


# In[45]:


y


# In[46]:


y = y.replace("\n", ",")


# In[47]:


y = y.replace("(" , ",")
y = y.replace(")", "")


# In[48]:


arr = y.split(",")


# In[49]:


speChar = ["\n", ",","(" , ",",")", ""]


# In[50]:


for num in range(len(speChar)//2):
    y = y.replace(speChar[num + num], speChar[num+1+num])


# In[73]:


food


# In[29]:


import requests
import sys
import webbrowser
import bs4
import os
import re
import wikipedia as wiki
import codecs
# from spellchecker import SpellChecker
import pandas as pd
import numpy as np
URLS = []
cancer_l = []
diabetes_l = []  
asthma_1 = []
heart_1 = []
inconclusive_1 = []
testing_1 = []
risk_1 = []
stomach_1 = []
liver_l = [] 
def checkUrl(url):
    p = urlparse(url)
    conn = http.client.HTTPConnection(p.netloc)
    conn.request('HEAD', p.path)
    resp = conn.getresponse()
    return resp.status < 400

def fixNames(foods):
    fixed = []
    for i in foods:
        fix = i
        if " " in i:
            fix = i[0:i.index(" ")+1]+ i[i.index(" ") +1:].lower()
            fix = fix.replace(' ', '_')
        fix = fix.capitalize()
        fixed.append(fix)
    return fixed

# def fixWords(foods):
#     spell = SpellChecker()
#     safe = []
#     f = open('badlist.txt', 'r')
#     for line in f:
#         safe.append(line.strip())
#     foods = [x.upper() for x in foods]
#     safe = [y.upper() for y in safe]
#     newWords = []
#     for i in foods:
#         bet = ""
#         if i in safe:
#             newWords.append(i)
#         elif " " not in i:
#             newWords.append(spell.correction(i))
#         else:
#             ary = i.split(" ")
#             for x in ary:
#                 bet += (spell.correction(x) + " ")
#             bet = bet[0:len(bet)-1]
#             newWords.append(bet)
#     return newWords
def health_check(carcin, food): #carcin is the disease ie Cancer, Diabetes, etc;
    heal = []
    for i in carcin:
        for j in food:
            if i in j and i not in heal:
                heal.append(i)
    return heal

def tierList(food):
  
    path = 'C:\\Users\\HP\\Desktop\\SigmaHacks\\Health Tier List\\TierList.csv'
    df = pd.read_csv(path)
    df.fillna('uuu', inplace = True)
    cancer = np.asanyarray(df['cancer'].str.upper())
    diabetes = np.asanyarray(df['diabetes'].str.upper())
    asthma = np.asanyarray(df['asthma'].str.upper())
    heart = np.asanyarray(df['Heart'].str.upper())
    risk = np.asanyarray(df['risk'].str.upper())
    stomach = np.asanyarray(df['stomach'].str.upper())
    liver = np.asanyarray(df['LIVER'].str.upper())
    food = [x.upper() for x in food]
    
    # Match the arr list generated by the GCP with possible risksx
    # 0: Cancer / 1: Diabetes /  2: Asthma  / 3: Heart / 4: Risk/  5: Stomach / 6: Liver
    cancer_l = health_check(cancer,food)
    diabetes_l = health_check(diabetes,food)
    asthma_l = health_check(asthma,food)
    heart_l = health_check(heart,food)
    risk_l = health_check(risk,food)
    stomach_l = health_check(stomach,food)
    liver_l = health_check(liver,food)
    cum_list = [cancer_l,diabetes_l,asthma_l,heart_l,risk_l,stomach_l,liver_l]
    
    # CONVERT TO THE URL VERSION OF THE SAME LIST l2 means the URL VERSION
    cancer_l2 = generateUrl(cancer_l)
    diabetes_l2 = generateUrl(diabetes_l)
    asthma_l2 = generateUrl(asthma_l)
    heart_l2 = generateUrl(heart_l)
    risk_l2 = generateUrl(risk_l)
    stomach_l2 = generateUrl(stomach_l)
    liver_l2 = generateUrl(liver_l)
    
    #CHECK WHICH CATEGORIES THE CARCINOGEN IS PART OF 
    used = []
    linkChecker(cancer_l,cancer_l2,used,cum_list)
    linkChecker(diabetes_l,diabetes_l2,used,cum_list)
    linkChecker(asthma_l,asthma_l2,used,cum_list)
    linkChecker(heart_l,heart_l2,used,cum_list)
    linkChecker(risk_l,risk_l2,used,cum_list)
    linkChecker(stomach_l,stomach_l2,used,cum_list)
    linkChecker(liver_l,liver_l2,used,cum_list)
    
def linkChecker(carcin_l,carcin_l2,used,cum_list): # adds the different links people check                
     if len(carcin_l2) > 0:
        for i in range(len(carcin_l)):
            if carcin_l[i] not in used:
                printed = carcin_l[i] + " causes "
                printed = addOns(carcin_l[i],cum_list,printed)
                print(printed)
                print("LEARN MORE ABOUT "+carcin_l[i]+" THROUGH THIS LINK: "+carcin_l2[i])
                used.append(carcin_l[i])  
                
def addOns(l,cumul,printed): #adds the different diseases and risks to the printed statement = multiple check
    numRisks = 0
    if l in cumul[0]: 
        printed += "cancer/ " 
        numRisks +=1
    if l in cumul[1]: 
        printed += "diabetes/ " 
        numRisks +=1
    if l in cumul[2]: 
        printed += "asthma/ " 
        numRisks +=1
    if l in cumul[3]: 
        printed += "heart disease/ "
        numRisks +=1
    if l in cumul[4]: 
        printed += "different risks (Check Link/Database for More Info)/ " 
        numRisks +=1
    if l in cumul[5]: 
        printed += "Stomachaches/ " 
        numRisks +=1
    if l in cumul[6]: 
        printed += "Liver Damage/ "
        numRisks +=1
    return printed[0:len(printed)-2]

def generateUrl(arr):
    arr = fixNames(arr)
    for i in range(len(arr)):
        j = arr[i]
        if j == "Yellow_6" or j == 'Yellow_6_lake' or j == 'Yellow_5_lake':
            urllink = "https://en.wikipedia.org/wiki/Sunset_Yellow_FCF"
        elif j == "Red_40" or j == "Red_40_lake":
            urllink = "https://en.wikipedia.org/wiki/Allura_Red_AC"
        elif j== "Blue_1":
            urllink = "https://en.wikipedia.org/wiki/Brilliant_Blue_FCF"
        else:
            urllink = "https://en.wikipedia.org/wiki/" + ''.join(j)
        #webbrowser.get('chrome').open(urllink)
        #if checkUrl(urllink):
        arr[i] = urllink
    return arr
def main():
    arr = ['INGREDIENT S',
 'DORITOS SALSA FLAVORED TORTILLA CHIPS',
 'Com',
 ' Veneable Oil ',
 'Com',
 ' Canola',
 ' and/or Sunflower Oil',
 ' and Less Than 2 % of the',
 'Fullowing: Maltodextrin ',
 'Made from Corm',
 ' Salt',
 ' Cheddar Cheese ',
 'Milk',
 ' Cheese',
 'Cuus',
 ' Sait',
 ' Enzymes',
 ' Monosodium Glutamate',
 ' Tomato Powder',
 ' Onion Powder',
 'Sugar',
 ' Sodium Diacetate',
 ' Corn Starch',
 ' Buttermilk',
 ' Romano Cheese',
 "Pat Skim Cow's Milk",
 ' Cheese Cultures',
 ' Sait',
 ' Enzymes',
 'Whey Protein Concentrate',
 'Com Syrup Solids',
 ' Fructose',
 ' Natural and Artificial Flavors',
 ' Lactose',
 'Spices',
 ' Garlic',
 'Powder',
 ' Citric Acid',
 'Skim Mik',
 'Artificial Color ',
 'Red 40 Lake',
 ' Yellow 6',
 ' Yelow 5',
 ' Yellow',
 '6 Lake',
 ' Yellow 5 Lake',
 ' Blue 1',
 ' Red 40',
 ' Malic Acid',
 ' Lime Juice',
 ' Lactic Acid',
 ' Sodium',
 'Caselhate',
 ' Disodium Inosinate and Disodium Guanylate.',
 'CONTAINS MILK INGREDIENTS',
 "MEETOS FLAMIN' HOTO CRUNCHY CHEESE FLAVORED SNACKS",
 'Thinmin Mononitrate',
 '',
 '']
    search = arr
    #search = fixWords(search)
    #search = fixNames(search)
    tierList(search)
    # for the google links    # requests
main()


# In[22]:


x = "asjkdhakdhaksmalto"


# In[23]:


e


# In[38]:


from PIL import Image

im = Image.open('Foto.jpg')
im.save('Foto.png') 


# In[39]:


import Image
im = Image.open("file.png")
im.save("file.jpg", "JPEG")

